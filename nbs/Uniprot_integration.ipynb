{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp uniprot_integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UniProt data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains functions to import a uniport annotation file and to format it as pandas dataframe for further usage in alphamap.\n",
    "\n",
    "The preprocessed uniprot annotation includes information about:  \n",
    "- __the known preprocessing events__ for proteins, such as signal peptide, transit peptide, propeptide, chain, peptide;\n",
    "- information on all available in Uniprot __post translational modificatios__, like modified residues (Phosphorylation, Methylation, Acetylation, etc.), Lipidation, Glycosylation, etc.;\n",
    "- information on __sequence similarities__ with other proteins and __the domain(s)__ present in a protein, such as domain, repeat, region, motif, etc.;\n",
    "- information on __the secondary and tertiary structure__ of proteins, such as turn, beta strand, helix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions on how to download a UniProt annotation file\n",
    "\n",
    "1. Go to the Uniprot website(https://www.uniprot.org/uniprot/), select the organism of interest in the \"Popular organisms\" section and click on it.\n",
    "2. Click the \"Download\" button and select \"Text\" format.\n",
    "3. Select the \"Compressed\" radio button and click \"Go\".\n",
    "4. Unzip the downloaded file and specify the path to this file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def extract_note(string: str, splitted:bool = False):\n",
    "    \"\"\"\n",
    "    Helper function to extract information about note of the protein from Uniprot using regular expression.\n",
    "\n",
    "    Args:\n",
    "        string (str): Uniprot annotation string.\n",
    "        splitted (bool, optional): Flag to allow linebreaks. Default is 'False'.\n",
    "    Returns:\n",
    "        str: Extracted string of the uniprot note section.\n",
    "    \"\"\"\n",
    "    if not splitted:\n",
    "        regex = r\"\\/note=\\\"(?P<note>.+?)\\\"\"\n",
    "    else:\n",
    "        regex = r\"\\/note=\\\"(?P<note>.*)\"\n",
    "    result = re.findall(regex, string)\n",
    "    return result\n",
    "\n",
    "def extract_note_end(string: str, has_mark:bool = True):\n",
    "    \"\"\"\n",
    "    Helper function to extract information about note of the protein from Uniprot using regular expression.\n",
    "\n",
    "    Args:\n",
    "        string (str): Uniprot annotation string.\n",
    "        has_mark (bool, optional): Flag if end quotation marks are present. Default is 'False'.\n",
    "    Returns:\n",
    "        str: Extracted string of the uniprot note section.\n",
    "    \"\"\"\n",
    "    if has_mark:\n",
    "        regex = r\"FT\\s+(?P<note>.*)\\\"\"\n",
    "    else:\n",
    "        regex = r\"FT\\s+(?P<note>.*)\"\n",
    "    result = re.findall(regex, string)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# write tests for extract_note and extract_note_end functions\n",
    "def test_extract_note_not_splitted():\n",
    "    string = 'FT                   /note=\"Missing (in isoform 2)\"'\n",
    "    output = extract_note(string)\n",
    "    assert \"Missing (in isoform 2)\" == output[0]\n",
    "    \n",
    "def test_extract_note_splitted():\n",
    "    string = 'FT                   /note=\"MAAALFVLLGF -> MKQSD'\n",
    "    output = extract_note(string, splitted=True)\n",
    "    assert \"MAAALFVLLGF -> MKQSD\" == output[0]\n",
    "    \n",
    "def test_extract_note_end_finished():\n",
    "    string = 'FT                   ASPQER (in isoform 4)\"'\n",
    "    output = extract_note_end(string)\n",
    "    assert \"ASPQER (in isoform 4)\" == output[0]\n",
    "    \n",
    "def test_extract_note_end_not_finished():\n",
    "    string = 'FT                   ASPQER (in isoform 4)'\n",
    "    output = extract_note_end(string, has_mark=False)\n",
    "    assert \"ASPQER (in isoform 4)\" == output[0]\n",
    "    \n",
    "test_extract_note_not_splitted()\n",
    "test_extract_note_splitted()\n",
    "test_extract_note_end_finished()\n",
    "test_extract_note_end_not_finished()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def resolve_unclear_position(value: str):\n",
    "    \"\"\"\n",
    "    Replace unclear position of the start/end of the modification defined as '?' with -1 and if it's defined as '?N'\n",
    "    or \">N\" - by removing the '?'/'>'/'<' signs.\n",
    "\n",
    "    Args:\n",
    "        value (str): Unclear sequence position from uniprot.\n",
    "    Returns:\n",
    "        float: Resolved sequence position.\n",
    "    \"\"\"\n",
    "    # if it's \"1..?\" or \"?..345\" for start or end -> remove -1 that we can filter later\n",
    "    # if it's \"31..?327\" or \"?31..327\" -> remove the question mark\n",
    "    # if it's \"<1..106\" or \"22..>115\" -> remove the \"<\" or \">\" signs\n",
    "    if value == '?':\n",
    "        return -1\n",
    "    value = value.replace('?', '').replace('>', '').replace('<', '')\n",
    "    return float(value)\n",
    "\n",
    "def extract_positions(posit_string: str):\n",
    "    \"\"\"\n",
    "    Extract isoform_id(str) and start/end positions(float) of any feature key from the string.\n",
    "\n",
    "    Args:\n",
    "        posit_string (str): Uniprot position string.\n",
    "    Returns:\n",
    "        [str, float, float]: str: Uniprot isoform accession, float: start position, float: end position\n",
    "    \"\"\"\n",
    "    isoform = ''\n",
    "    start = end = np.nan\n",
    "    if '..' in posit_string:\n",
    "        start, end = posit_string.split('..')\n",
    "    if ':' in posit_string:\n",
    "        if isinstance(start, str):\n",
    "            isoform, start = start.split(':')\n",
    "        else:\n",
    "            isoform, start = posit_string.split(':')\n",
    "    # in the case when we have only one numeric value as a posit_string\n",
    "    if isinstance(start, float):\n",
    "        start = posit_string\n",
    "    # change the type of start and end into int/float(np.nan)\n",
    "    if isinstance(start, str):\n",
    "        start = resolve_unclear_position(start)\n",
    "    if isinstance(end, str):\n",
    "        end = resolve_unclear_position(end)\n",
    "    return isoform, start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# write tests for extract_positions and resolve_unclear_position functions\n",
    "def test_extract_positions():\n",
    "    string = '34..65'\n",
    "    isoform, start, end = extract_positions(string)\n",
    "    np.testing.assert_equal(['', 34, 65], [isoform, start, end])\n",
    "\n",
    "def test_extract_positions_with_isoform():\n",
    "    string = 'P35613-2:195..199'\n",
    "    isoform, start, end = extract_positions(string)\n",
    "    np.testing.assert_equal(['P35613-2', 195, 199], [isoform, start, end])\n",
    "\n",
    "def test_extract_positions_start_with_isoform():\n",
    "    string = 'Q9C0I9-2:256'\n",
    "    isoform, start, end = extract_positions(string)\n",
    "    np.testing.assert_equal(['Q9C0I9-2', 256, np.nan], [isoform, start, end])\n",
    "    \n",
    "def test_extract_positions_start():\n",
    "    string = '256'\n",
    "    isoform, start, end = extract_positions(string)\n",
    "    np.testing.assert_equal(['', 256, np.nan], [isoform, start, end])\n",
    "\n",
    "def test_resolve_unclear_position_unknown():\n",
    "    string = '?'\n",
    "    message = f\"For unknown position resolve_unclear_position function returns wrong output instead of -1.\"\n",
    "    assert -1 == resolve_unclear_position(string), message\n",
    "    \n",
    "def test_resolve_unclear_position_unclear():\n",
    "    string1 = '>117'\n",
    "    string2 = '<1'\n",
    "    string3 = '?327'\n",
    "    string4 = '?10'\n",
    "    message = f\"For unclear position resolve_unclear_position function returns wrong output.\"\n",
    "    assert 117 == resolve_unclear_position(string1), message\n",
    "    assert 1 == resolve_unclear_position(string2), message\n",
    "    assert 327 == resolve_unclear_position(string3), message\n",
    "    assert 10 == resolve_unclear_position(string4), message\n",
    "\n",
    "test_extract_positions()\n",
    "test_extract_positions_with_isoform()\n",
    "test_extract_positions_start_with_isoform()\n",
    "test_extract_positions_start()\n",
    "test_resolve_unclear_position_unknown() \n",
    "test_resolve_unclear_position_unclear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniprot preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def preprocess_uniprot(path_to_file: str):\n",
    "    \"\"\"\n",
    "    A complex complete function to preprocess Uniprot data from specifying the path to a flat text file\n",
    "    to the returning a dataframe containing information about:\n",
    "        - protein_id(str)\n",
    "        - feature(category)\n",
    "        - isoform_id(str)\n",
    "        - start(float)\n",
    "        - end(float)\n",
    "        - note information(str)\n",
    "\n",
    "    Args:\n",
    "        path_to_file (str): Path to a .txt annotation file directly downloaded from uniprot.\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with formatted uniprot annotations for alphamap.\n",
    "\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    with open(path_to_file) as f:\n",
    "\n",
    "        is_splitted = False\n",
    "        new_instance = False\n",
    "        combined_note = []\n",
    "        line_type = ''\n",
    "\n",
    "        for line in f:\n",
    "\n",
    "            if line.startswith(('AC', 'FT')):\n",
    "                if is_splitted:\n",
    "                    # in case when the note information is splitted into several lines\n",
    "                    if line.rstrip().endswith('\"'):\n",
    "                        # if it's the final part of the note\n",
    "                        combined_note.extend(extract_note_end(line))\n",
    "                        all_data.append([protein_id, feature, isoform, start, end, \" \".join(combined_note)])\n",
    "                        is_splitted = False\n",
    "                        new_instance = False\n",
    "                    else:\n",
    "                        # if it's the middle part of the note\n",
    "                        combined_note.extend(extract_note_end(line, has_mark=False))\n",
    "                elif line.startswith('AC'):\n",
    "                    # contains the protein_id information\n",
    "                    if line_type != 'AC':\n",
    "                        # to prevent a situation when the protein has several AC lines with different names\n",
    "                        # in this case we are taking the first name in the first line\n",
    "                        protein_id = line.split()[1].replace(';', '')\n",
    "                    line_type = 'AC'\n",
    "                elif line.startswith('FT'):\n",
    "                    line_type = 'FT'\n",
    "                    # contains all modifications/preprocessing events/etc., their positions, notes\n",
    "                    data = line.split()\n",
    "                    if data[1].isupper() and not data[1].startswith('ECO'):\n",
    "                            feature = data[1]\n",
    "                            isoform, start, end = extract_positions(data[2])\n",
    "                            new_instance = True\n",
    "                    else:\n",
    "                        if data[1].startswith('/note'):\n",
    "                            note = extract_note(line)\n",
    "                            if note:\n",
    "                                # if note was created > it contains just one line and can be already added to the data\n",
    "                                all_data.append([protein_id, feature, isoform, start, end, note[0]])\n",
    "                                new_instance = False\n",
    "                            else:\n",
    "                                # if note is empty > it's splitted into several lines and we create combined_note\n",
    "                                combined_note = extract_note(line, splitted=True)\n",
    "                                is_splitted = True\n",
    "                        else:\n",
    "                            if new_instance:\n",
    "                                # in case when we don't have any note but need to add other information about instance\n",
    "                                all_data.append([protein_id, feature, isoform, start, end, ''])\n",
    "                                new_instance = False\n",
    "\n",
    "    # create a dataframe for preprocessed data\n",
    "    uniprot_df = pd.DataFrame(all_data, columns=['protein_id', 'feature', 'isoform_id', 'start', 'end', 'note'])\n",
    "    # change the dtypes of the columns\n",
    "    uniprot_df.feature = uniprot_df.feature.astype('category')\n",
    "    # to filter the instances that don't have a defined start/end position(start=-1 or end=-1)\n",
    "    uniprot_df = uniprot_df[(uniprot_df.start != -1) & (uniprot_df.end != -1)].reset_index(drop=True)\n",
    "\n",
    "    return uniprot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# for testing of the function a text file for P11532 protein was downloaded from the Uniprot\n",
    "path_to_test_file = '../testdata/P11532_test_file.txt'\n",
    "\n",
    "def test_preprocess_uniprot():\n",
    "    \n",
    "    test_df = preprocess_uniprot(path_to_test_file)\n",
    "    np.testing.assert_equal((167, 6), test_df.shape, err_msg = 'The shape of the returned file is incorrect.')\n",
    "    assert test_df.feature.dtype == 'category', 'The type of the feature column is not a category.'\n",
    "\n",
    "    # to check the cases when protein had no note but had feature, start and end, f.e.\n",
    "    # FT   HELIX           14..31\n",
    "    # FT                   /evidence=\"ECO:0000244|PDB:1DXX\"\n",
    "    np.testing.assert_array_equal(['P11532', 'HELIX', '', 14.0, 31.0, ''], \n",
    "                                  test_df[(test_df.feature == 'HELIX') & (test_df.start == 14)].values.tolist()[0],\n",
    "                                 err_msg = \"The output for the protein that doesn't have a note but has \\\n",
    "                                 feature information, a start and an end position is incorrect.\")\n",
    "\n",
    "    # to check the cases when protein had a note written in one line and doesn't have end, f.e.\n",
    "    # FT   MOD_RES         3500\n",
    "    # FT                   /note=\"Phosphoserine\"\n",
    "    np.testing.assert_array_equal(['P11532', 'MOD_RES', '', 3500.0, np.nan, 'Phosphoserine'],\n",
    "                                  test_df[(test_df.feature == 'MOD_RES') & (test_df.start == 3500)].values.tolist()[0],\n",
    "                                 err_msg = \"The output for the protein that has the note written in one line \\\n",
    "                                 and doesn't have an end position for the feature is incorrect.\")\n",
    "\n",
    "    # to check the cases when protein had a note split into several line, f.e.\n",
    "    # FT   VARIANT         3340\n",
    "    # FT                   /note=\"C -> Y (in DMD; results in highly reduced protein\n",
    "    # FT                   levels and expression at the sarcolemma)\"\n",
    "    assert 'C -> Y (in DMD; results in highly reduced protein levels and expression at the sarcolemma)' == \\\n",
    "    test_df[(test_df.feature == 'VARIANT') & (test_df.start == 3340)]['note'].values[0], \\\n",
    "    \"The output for the protein that has a note split into several lines is incorrect.\"\n",
    "\n",
    "    # to check the cases when protein had protein_ids written in several line, f.e.\n",
    "    # AC   P11532; A1L0U9; E7EQR9; E7EQS5; E7ESB2; E9PDN1; E9PDN5; F5GZY3; F8VX32;\n",
    "    # AC   Q02295; Q14169; Q14170; Q5JYU0; Q6NSJ9; Q7KZ48; Q8N754; Q9UCW3; Q9UCW4;\n",
    "    assert 1 == test_df.protein_id.nunique(), \"A preprocess_uniprot function returns a non-unique protein_id.\"\n",
    "    assert 'P11532' == test_df.protein_id.unique()[0], 'A preprocess_uniprot function returns a wrong protein_id.'\n",
    "\n",
    "test_preprocess_uniprot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UniProt feature dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a dictionary that maps feature names to the feature entries in the processed uniprot annotation file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "uniprot_feature_dict = {\n",
    "    'Chain': 'CHAIN',\n",
    "    'Initiator methionine': 'INIT_MET',\n",
    "    'Peptide': 'PEPTIDE',\n",
    "    'Propeptide': 'PROPEP',\n",
    "    'Signal peptide': 'SIGNAL',\n",
    "    'Transit peptide': 'TRANSIT',\n",
    "    'Cross-link': 'CROSSLNK',\n",
    "    'Disulfide bond': 'DISULFID',\n",
    "    'Glycosylation': 'CARBOHYD',\n",
    "    'Lipidation': 'LIPID',\n",
    "    'Modified residue': 'MOD_RES',\n",
    "    'Coiled coil': 'COILED',\n",
    "    'Compositional bias': 'COMPBIAS',\n",
    "    'Domain': 'DOMAIN',\n",
    "    'Motif': 'MOTIF',\n",
    "    'Region': 'REGION',\n",
    "    'Repeat': 'REPEAT',\n",
    "    'Zinc finger': 'ZN_FING',\n",
    "    'Intramembrane': 'INTRAMEM',\n",
    "    'Topological domain': 'TOPO_DOM',\n",
    "    'Transmembrane': 'TRANSMEM',\n",
    "    'Beta strand': 'STRAND',\n",
    "    'Helix': 'HELIX',\n",
    "    'Turn': 'TURN',\n",
    "    'Active site': 'ACT_SITE',\n",
    "    'Binding site': 'BINDING',\n",
    "    'Calcium binding': 'CA_BIND',\n",
    "    'DNA binding': 'DNA_BIND',\n",
    "    'Metal binding': 'METAL',\n",
    "    'Nucleotide binding': 'NP_BIND',\n",
    "    'Site': 'SITE',\n",
    "    'Non-standard residue': 'NON_STD',\n",
    "    'Non-adjacent residues': 'NON_CONS',\n",
    "    'Non-terminal residue': 'NON_TER',\n",
    "    'Natural variant': 'VARIANT',\n",
    "    'Sequence conflict': 'CONFLICT',\n",
    "    'Alternative sequence': 'VAR_SEQ',\n",
    "    'Sequence uncertainty': 'UNSURE',\n",
    "    'Secondary structure': 'STRUCTURE',\n",
    "    'Mutagenesis': 'MUTAGEN'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "###### Export notebook to script ###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
